{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "00f428d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import  pyspark.sql. functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = SparkSession.builder.appName(\"iFood Case\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "905c0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/marco/ifood-case'\n",
    "DATA_RAW_PATH = BASE_PATH + '/data/raw/'\n",
    "DATA_PROCESSED_PATH = BASE_PATH + '/data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1381d",
   "metadata": {},
   "source": [
    "## Profile Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1ee7624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile = spark.read.json(DATA_RAW_PATH + 'profile.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "70c36bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile_processed = (\n",
    "    df_profile\n",
    "    .filter(F.col('age') <= 101)\n",
    "    .withColumn('registered_on', F.to_date(F.col('registered_on'), 'yyyyMMdd'))\n",
    "    .withColumn('actual_date', F.lit('2019-01-01').cast('date'))\n",
    "    .fillna({'gender': 'O'})\n",
    "    .select([\n",
    "        F.col('id').alias('account_id'),\n",
    "        F.col('age'),\n",
    "        F.datediff(F.col('actual_date'), F.col('registered_on')).alias('registered_days'),\n",
    "        F.when(F.col('gender') == 'F', 1).otherwise(0).alias('gender_F'),\n",
    "        F.when(F.col('gender') == 'M', 1).otherwise(0).alias('gender_M'),\n",
    "        F.when(F.col('gender') == 'O', 1).otherwise(0).alias('gender_O'),\n",
    "    ])\n",
    "    .dropDuplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "db0e03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile_processed.toPandas().to_csv(DATA_PROCESSED_PATH + 'profile_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe26d57",
   "metadata": {},
   "source": [
    "## Offers Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a00e59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offers = spark.read.json(DATA_RAW_PATH + 'offers.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "89ce6eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_list = ['web', 'email', 'mobile', 'social']\n",
    "\n",
    "for ch in channels_list:\n",
    "    df_offers = df_offers.withColumn(f'channel_{ch}', \n",
    "        F.array_contains(F.col('channels'), ch).cast(T.IntegerType()))\n",
    "\n",
    "df_offers_processed = (\n",
    "    df_offers\n",
    "    .select([\n",
    "        F.col('id').alias('offer_id'),\n",
    "        F.col('offer_type'),\n",
    "        F.col('discount_value'),\n",
    "        F.col('min_value'),\n",
    "        F.col('duration'),\n",
    "        F.col('channel_web'),\n",
    "        F.col('channel_email'),\n",
    "        F.col('channel_mobile'),\n",
    "        F.col('channel_social'),\n",
    "    ])\n",
    "    .dropDuplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8cd56cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offers_processed.toPandas().to_csv(DATA_PROCESSED_PATH + 'offers_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f23dfa7",
   "metadata": {},
   "source": [
    "## Transaction Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a90b00ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_transaction_events = spark.read.json(DATA_RAW_PATH + 'transactions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9330eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event_transaction_processed = (\n",
    "    df_transaction_events\n",
    "    .filter(F.col('event') == 'transaction')\n",
    "    .select([\n",
    "        F.col('account_id'), \n",
    "        F.col('value.amount').alias('amount'), \n",
    "        F.col('time_since_test_start').alias('transaction_time'),\n",
    "    ])\n",
    ")\n",
    "\n",
    "df_event_offer_received_processed = (\n",
    "    df_transaction_events\n",
    "    .filter(F.col('event') == 'offer received')\n",
    "    .select([\n",
    "        F.col('account_id'),\n",
    "        F.col('value.offer id').alias('offer_id'),\n",
    "        F.col('time_since_test_start').alias('received_time'),\n",
    "    ])\n",
    ")\n",
    "\n",
    "df_event_offer_viewed_processed = (\n",
    "    df_transaction_events\n",
    "    .filter(F.col('event') == 'offer viewed')\n",
    "    .select([\n",
    "        F.col('account_id'),\n",
    "        F.col('value.offer id').alias('offer_id'),\n",
    "        F.col('time_since_test_start').alias('viewed_time'),\n",
    "    ])\n",
    ")\n",
    "\n",
    "df_event_offer_completed_processed = (\n",
    "    df_transaction_events\n",
    "    .filter(F.col('event') == 'offer completed')\n",
    "    .select([\n",
    "        F.col('account_id'),\n",
    "        F.col('value.offer_id').alias('offer_id'),\n",
    "        F.col('value.reward').alias('reward'),\n",
    "        F.col('time_since_test_start').alias('transaction_time'),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ba368bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_event_transaction_processed.toPandas().to_csv(DATA_PROCESSED_PATH + 'event_transaction_processed.csv', index=False)\n",
    "df_event_offer_received_processed.toPandas().to_csv(DATA_PROCESSED_PATH + 'event_offer_received_processed.csv', index=False)\n",
    "df_event_offer_viewed_processed.toPandas().to_csv(DATA_PROCESSED_PATH + 'event_offer_viewed_processed.csv', index=False)\n",
    "df_event_offer_completed_processed.toPandas().to_csv(DATA_PROCESSED_PATH + 'event_offer_completed_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
